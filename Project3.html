<!DOCTYPE HTML>
<html>
	<head>
		<title>Project: Agentic Model Validation for CRE Logistic Regression</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<a href="index.html" class="logo">Agentic Model Validation for CRE Logistic Regression</a>
					</header>

				<!-- Nav -->
					<nav id="nav">
						<ul class="links">
							<li><a href="index.html">Home</a></li>
							<li><a href="generic.html">About Me</a></li>
							<li class="active"><a href="Project3.html">Project</a></li>
						</ul>
						<ul class="icons">
							<li><a href="https://www.linkedin.com/in/dagoberto-farias/" class="icon brands fa-linkedin"><span class="label">LinkedIn</span></a></li>
							<li><a href="https://github.com/tenken127" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
						</ul>
					</nav>

				<!-- Main -->
					<div id="main">

						<!-- Post -->
							<section class="post">
								<header class="major">
									<h1>Agentic Model Validation for<br />CRE Logistic Regression</h1>
									<p>A full validation lifecycle for a commercial real estate default model,<br />
									showing how specialized agents improve speed, consistency, and traceability.</p>
								</header>

								<h3>Business Problem</h3>
								<p>Traditional validation cycles can be manual, fragmented, and documentation-heavy.  This project
								demonstrates how an Agentic workflow can accelerate validation for a Logistic Regression PD model 
								without sacrificing governance rigor.  In a smaller organization with fewer resources and data 
								scientists to cover the portfolio, this becomes a substantial pain point.  The advent of AI agents 
								allows many of these procedures to be automated, requiring less time devoted to the tedious elements 
								of the validation, while increasing the quality of model validations overall.  We are exploring here 
								how to structure a model validation using agents to orchestrate the testing of a commercial (CRE) credit PD 
								model using synthetic data.</p>

								<h3>Model Context</h3>
								<p>The model is a loan-level logistic regression predicting <code>default_flag</code> using
								credit, collateral, and market features such as <code>ltv</code>, <code>dscr</code>,
								<code>debt_yield</code>, <code>occupancy_rate</code>, market vacancy, and regional factors.
								Validation covers conceptual soundness, data quality, performance testing, stability, and
								segment-level fairness diagnostics.</p>

								<h3>Model Specifications &amp; Parameter Weights</h3>
								<ul>
									<li><strong>Model type:</strong> Logistic Regression (binary classification)</li>
									<li><strong>Target:</strong> <code>default_flag</code></li>
									<li><strong>Estimation lens:</strong> Coefficients shown in log-odds units, with odds-ratio interpretation for business users</li>
									<li><strong>Validation note:</strong> Parameter direction and significance are reviewed alongside AUC/KS, not in isolation</li>
								</ul>

								<div class="table-wrapper">
									<table>
										<thead>
											<tr>
												<th>Variable</th>
												<th>Coefficient (Beta)</th>
												<th>Approx. Odds Ratio</th>
												<th>p-value</th>
												<th>Influence on Default Risk</th>
											</tr>
										</thead>
										<tbody>
											<tr>
												<td><code>watchlist_flag</code></td>
												<td>+1.335</td>
												<td>3.80x</td>
												<td>0.0005</td>
												<td>Strong positive and statistically significant risk signal.</td>
											</tr>
											<tr>
												<td><code>ltv</code></td>
												<td>+1.263</td>
												<td>3.54x</td>
												<td>0.4000</td>
												<td>Higher leverage increases predicted risk, though weak significance in this run.</td>
											</tr>
											<tr>
												<td><code>dscr</code></td>
												<td>-0.380</td>
												<td>0.68x</td>
												<td>0.4265</td>
												<td>Higher debt-service coverage lowers predicted risk directionally.</td>
											</tr>
											<tr>
												<td><code>noi_growth</code></td>
												<td>-1.561</td>
												<td>0.21x</td>
												<td>0.3200</td>
												<td>Improving NOI growth decreases risk directionally.</td>
											</tr>
											<tr>
												<td><code>market_vacancy</code></td>
												<td>+2.901</td>
												<td>18.19x</td>
												<td>0.3039</td>
												<td>Higher market vacancy pushes model toward higher default probability.</td>
											</tr>
											<tr>
												<td><code>unemployment_rate</code></td>
												<td>-14.668</td>
												<td>~0.00x</td>
												<td>0.0433</td>
												<td>Significant coefficient with non-intuitive sign; requires challenge, segmentation review, and potential redevelopment diagnostics.</td>
											</tr>
										</tbody>
									</table>
								</div>

								<p>These weights show why parameter review is a human-intensive validation step: beyond statistical significance, validators must test
								economic plausibility, multicollinearity effects, and segment behavior before deciding whether to recalibrate or redevelop.</p>

								<h3>Data Retrieval and Wrangling</h3>
								<p>A realistic synthetic CRE dataset was generated to emulate production constraints:
								class imbalance, missingness, outliers, and regime shifts. Agent-driven data pipelines
								then perform schema checks, imputations, encoding, and deterministic train/validation/test
								time splits before statistical testing begins.</p>
								<span class="image fit"><img src="images/cre_agent_flow.png" alt="Agent flow in validation framework" /></span>

								<h3>Validation Framework</h3>
								<ul>
									<li><strong>Discrimination:</strong> ROC-AUC, KS, Gini</li>
									<li><strong>Calibration:</strong> Brier score and grouped calibration checks</li>
									<li><strong>Classification Quality:</strong> precision, recall, F1, confusion matrix</li>
									<li><strong>Stability:</strong> PSI and temporal performance consistency</li>
									<li><strong>Statistical Significance:</strong> Wald and likelihood-ratio testing</li>
									<li><strong>Segment Review:</strong> by property type, MSA, and market-cap bucket</li>
								</ul>
								<span class="image fit"><img src="images/cre_model_metrics.png" alt="Validation performance metrics" /></span>
								<span class="image fit"><img src="images/cre_roc_curve.png" alt="ROC curve for CRE logistic regression model" /></span>
								<span class="image fit"><img src="images/cre_confusion_matrix.png" alt="Confusion matrix for CRE model validation" /></span>
								<span class="image fit"><img src="images/cre_segment_auc.png" alt="Segment-level AUC chart" /></span>
								<span class="image fit"><img src="images/cre_psi_top_features.png" alt="PSI drift chart" /></span>

								<h3>Validation Performance Interpretation</h3>
								<p>The ROC-AUC result indicates weak class separation in this validation run, which is a critical governance signal.
								From a model risk perspective, this is exactly where human judgment remains essential: a validator should not simply
								accept automated outputs, but determine whether the observed weakness points to <strong>recalibration</strong> or a
								more fundamental <strong>model redevelopment</strong> decision.</p>

								<p>A practical escalation approach is to anchor actions to internal model development standards and approved thresholds.
								For example, if discrimination is marginal but stability and calibration remain within tolerance, a controlled
								recalibration may be appropriate. If discrimination, calibration, and segment performance all deteriorate together,
								that combination is typically evidence for redevelopment rather than incremental tuning.</p>

								<p>In other words, agents accelerate testing, evidence collection, and consistency, but <strong>do not replace</strong>
								the evaluator's responsibility to challenge results, interpret context, and decide the risk disposition of the model
								before production use.</p>

								<h4>Decision Policy Table</h4>
								<div class="table-wrapper">
									<table>
										<thead>
											<tr>
												<th>Validation Signal</th>
												<th>Indicative Range</th>
												<th>Action Required</th>
											</tr>
										</thead>
										<tbody>
											<tr>
												<td>Discrimination (AUC / KS)</td>
												<td>AUC >= 0.70 and KS >= 0.25</td>
												<td>Maintain model with routine monitoring.</td>
											</tr>
											<tr>
												<td>Discrimination (AUC / KS)</td>
												<td>0.60 <= AUC < 0.70 or 0.15 <= KS < 0.25</td>
												<td>Targeted recalibration and tighter performance monitoring window.</td>
											</tr>
											<tr>
												<td>Discrimination (AUC / KS)</td>
												<td>AUC < 0.60 or KS < 0.15</td>
												<td>Escalate for redevelopment review and usage restrictions.</td>
											</tr>
											<tr>
												<td>Stability (PSI)</td>
												<td>PSI < 0.10</td>
												<td>No drift action required beyond standard controls.</td>
											</tr>
											<tr>
												<td>Stability (PSI)</td>
												<td>0.10 <= PSI < 0.25</td>
												<td>Yellow flag: investigate drift sources and consider recalibration.</td>
											</tr>
											<tr>
												<td>Stability (PSI)</td>
												<td>PSI >= 0.25</td>
												<td>Red flag: immediate review, possible model redevelopment trigger.</td>
											</tr>
										</tbody>
									</table>
								</div>

								<h3>Agentic Workflow</h3>
								<p>The project decomposes validation into specialized agents:
								<code>IntakeAgent</code>, <code>DataAgent</code>, <code>WrangleAgent</code>,
								<code>StatsTestAgent</code>, <code>DocReviewAgent</code>, <code>EvidencePackAgent</code>,
								<code>QAControlAgent</code>, and <code>WebsiteNarrativeAgent</code>. Each agent owns specific
								controls and outputs an auditable artifact.</p>

								<h3>How Agents Speed Up Validation</h3>
								<p>Manual vs agent-assisted KPI tracking is used to quantify impact. In the benchmark setup,
								agent-assisted validation reduced cycle time, increased controls executed, improved documentation
								completeness, and raised reproducibility pass rates. This supports scalable validation in high-volume
								model inventories.</p>
								<span class="image fit"><img src="images/cre_manual_vs_agent_kpis.png" alt="Manual vs agent-assisted KPI comparison" /></span>

								<h3>Governance Implications</h3>
								<p>The workflow aligns to SR 11-7 principles: conceptual soundness, ongoing monitoring, and outcomes analysis.
								Agents do not replace independent judgment; they systematize evidence collection and free validators
								to focus on challenge, interpretation, and risk decisions.</p>

								<h3>Key Takeaways</h3>
								<p></p>Data scientists must still be involved in each step of the process but agents are better utilized in the orchestration 
								of each of those stages, including the usage of existing code, whether Python or R used in statistical testing.	Depending upon LLMs 
								to produce statistical test results can often be fraught with errors.  However, using agents as orchestrators to pull, prep, and 
								invoke data as well as existing test scripts improves the process overall.</p>		
								<ul>
									<li>Agentic validation improves throughput while maintaining control discipline.</li>
									<li> Limited resources can more efficiently be utilized in smaller organizations.</li>
									<li>Documentation quality and auditability can be engineered as first-class outputs.</li>
								</ul>

								<ul class="actions special" style="margin-top: 2em;">
									<li><a href="index.html" class="button large">Back to Home</a></li>
								</ul>

							</section>

					</div>

				<!-- Footer -->
					<footer id="footer">
						<section class="split contact">
							<section>
								<h3>Email</h3>
								<p><a href="mailto: dagfarias127@gmail.com">dagfarias127@gmail.com</a></p>
							</section>
							<section>
								<h3>Social</h3>
								<ul class="icons alt">
									<li><a href="https://www.linkedin.com/in/dagoberto-farias/" class="icon brands alt fa-linkedin"><span class="label">LinkedIn</span></a></li>
									<li><a href="https://github.com/tenken127" class="icon brands alt fa-github"><span class="label">GitHub</span></a></li>
								</ul>
							</section>
						</section>
					</footer>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
